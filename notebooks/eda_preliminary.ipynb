{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary EDA - Data Quality Hell\n",
    "\n",
    "This notebook covers the initial inspection and cleaning of the **Model Case** dataset (January 1st - 15th, 2026). \n",
    "\n",
    "**Objective:** Prepare the data for deeper Exploratory Data Analysis (EDA) and future transformations using a stable, reproducible snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:26.896302Z",
     "iopub.status.busy": "2026-01-20T22:36:26.889841Z",
     "iopub.status.idle": "2026-01-20T22:36:27.630866Z",
     "shell.execute_reply": "2026-01-20T22:36:27.628570Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "We start with the merged **Model Case** dataset containing 39,844 records from 19 countries extracted for the Jan 1-15 period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:27.634017Z",
     "iopub.status.busy": "2026-01-20T22:36:27.634017Z",
     "iopub.status.idle": "2026-01-20T22:36:28.240771Z",
     "shell.execute_reply": "2026-01-20T22:36:28.240771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (39844, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>adref</th>\n",
       "      <th>location</th>\n",
       "      <th>created</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at</td>\n",
       "      <td>This position is posted by Jobgether on behalf of a partner company. We are currently looking fo...</td>\n",
       "      <td>Data Analyst (Growth)</td>\n",
       "      <td>5586892007</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTg2ODkyMDA3In0.t3OPQgJ6S0E...</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-15T21:42:20Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d) * Greentube GmbH * Vienna * Presence / Mobile * Publish...</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTg1MzU4MTk4In0.GEz4ubleXJ8...</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15T02:15:16Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at</td>\n",
       "      <td>Im AI &amp; Data Team bei Accenture vereinen wir einzigartige Persönlichkeiten und zukunftsgerich t ...</td>\n",
       "      <td>AI &amp; Data Science Analyst (all genders)</td>\n",
       "      <td>5582988482</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyOTg4NDgyIn0.k-K8zDLzgah...</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-13T21:37:41Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>Kitzbühel | Hybrides Arbeiten | Modebranche |  Datenstrategie | Interesse an AI willkommen Du l...</td>\n",
       "      <td>Data Analyst &amp; Engineer (m/w/d) Retail &amp; Marketing, Umzug nach Tirol?</td>\n",
       "      <td>5582082437</td>\n",
       "      <td>ANGEHEUERT GmbH Personalberatung</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyMDgyNDM3In0.HjKCxxMdYSY...</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-13T11:32:57Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at</td>\n",
       "      <td>Kitzbühel | Hybrides Arbeiten | Modebranche |  Datenstrategie | Interesse an AI willkommen Du l...</td>\n",
       "      <td>Senior Data Analyst (m/w/d) Google Analytics 4, Looker Studio, Power BI, SQL</td>\n",
       "      <td>5582082438</td>\n",
       "      <td>ANGEHEUERT GmbH Personalberatung</td>\n",
       "      <td>eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyMDgyNDM4In0.RQecAXsFJVE...</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-13T11:32:57Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code  \\\n",
       "0           at   \n",
       "1           at   \n",
       "2           at   \n",
       "3           at   \n",
       "4           at   \n",
       "\n",
       "                                                                                           description  \\\n",
       "0  This position is posted by Jobgether on behalf of a partner company. We are currently looking fo...   \n",
       "1  Product Owner - Data & Analytics (f/m/d) * Greentube GmbH * Vienna * Presence / Mobile * Publish...   \n",
       "2  Im AI & Data Team bei Accenture vereinen wir einzigartige Persönlichkeiten und zukunftsgerich t ...   \n",
       "3   Kitzbühel | Hybrides Arbeiten | Modebranche |  Datenstrategie | Interesse an AI willkommen Du l...   \n",
       "4   Kitzbühel | Hybrides Arbeiten | Modebranche |  Datenstrategie | Interesse an AI willkommen Du l...   \n",
       "\n",
       "                                                                          title  \\\n",
       "0                                                         Data Analyst (Growth)   \n",
       "1                                      Product Owner - Data & Analytics (f/m/d)   \n",
       "2                                       AI & Data Science Analyst (all genders)   \n",
       "3         Data Analyst & Engineer (m/w/d) Retail & Marketing, Umzug nach Tirol?   \n",
       "4  Senior Data Analyst (m/w/d) Google Analytics 4, Looker Studio, Power BI, SQL   \n",
       "\n",
       "           id                           company  \\\n",
       "0  5586892007                         Jobgether   \n",
       "1  5585358198                    Greentube GmbH   \n",
       "2  5582988482                         Accenture   \n",
       "3  5582082437  ANGEHEUERT GmbH Personalberatung   \n",
       "4  5582082438  ANGEHEUERT GmbH Personalberatung   \n",
       "\n",
       "                                                                                                 adref  \\\n",
       "0  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTg2ODkyMDA3In0.t3OPQgJ6S0E...   \n",
       "1  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTg1MzU4MTk4In0.GEz4ubleXJ8...   \n",
       "2  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyOTg4NDgyIn0.k-K8zDLzgah...   \n",
       "3  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyMDgyNDM3In0.HjKCxxMdYSY...   \n",
       "4  eyJhbGciOiJIUzI1NiJ9.eyJzIjoiUU9EQVBLXzA4QkdDUS1YTGJsY0g4USIsImkiOiI1NTgyMDgyNDM4In0.RQecAXsFJVE...   \n",
       "\n",
       "           location               created   search_term  \n",
       "0        Österreich  2026-01-15T21:42:20Z  Data Analyst  \n",
       "1  Wien, Österreich  2026-01-15T02:15:16Z  Data Analyst  \n",
       "2        Österreich  2026-01-13T21:37:41Z  Data Analyst  \n",
       "3  Wien, Österreich  2026-01-13T11:32:57Z  Data Analyst  \n",
       "4        Österreich  2026-01-13T11:32:57Z  Data Analyst  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_csv = Path(\"../data/interim/all_jobs_merged.csv\")\n",
    "df = pd.read_csv(input_csv)\n",
    "print(f\"Initial Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drop Unnecessary Columns\n",
    "\n",
    "Columns `description` (too inconsistent) and `adref` (no analytical value) are dropped to simplify the analysis.\n",
    "\n",
    "> **Note:** We use `errors='ignore'` so the cell can be re-run without errors if the columns were already removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:28.300545Z",
     "iopub.status.busy": "2026-01-20T22:36:28.300545Z",
     "iopub.status.idle": "2026-01-20T22:36:28.321789Z",
     "shell.execute_reply": "2026-01-20T22:36:28.321789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>created</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at</td>\n",
       "      <td>Data Analyst (Growth)</td>\n",
       "      <td>5586892007</td>\n",
       "      <td>Jobgether</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-15T21:42:20Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15T02:15:16Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>at</td>\n",
       "      <td>AI &amp; Data Science Analyst (all genders)</td>\n",
       "      <td>5582988482</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-13T21:37:41Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>Data Analyst &amp; Engineer (m/w/d) Retail &amp; Marketing, Umzug nach Tirol?</td>\n",
       "      <td>5582082437</td>\n",
       "      <td>ANGEHEUERT GmbH Personalberatung</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-13T11:32:57Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Data Analyst (m/w/d) Google Analytics 4, Looker Studio, Power BI, SQL</td>\n",
       "      <td>5582082438</td>\n",
       "      <td>ANGEHEUERT GmbH Personalberatung</td>\n",
       "      <td>Österreich</td>\n",
       "      <td>2026-01-13T11:32:57Z</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country_code  \\\n",
       "0           at   \n",
       "1           at   \n",
       "2           at   \n",
       "3           at   \n",
       "4           at   \n",
       "\n",
       "                                                                          title  \\\n",
       "0                                                         Data Analyst (Growth)   \n",
       "1                                      Product Owner - Data & Analytics (f/m/d)   \n",
       "2                                       AI & Data Science Analyst (all genders)   \n",
       "3         Data Analyst & Engineer (m/w/d) Retail & Marketing, Umzug nach Tirol?   \n",
       "4  Senior Data Analyst (m/w/d) Google Analytics 4, Looker Studio, Power BI, SQL   \n",
       "\n",
       "           id                           company          location  \\\n",
       "0  5586892007                         Jobgether        Österreich   \n",
       "1  5585358198                    Greentube GmbH  Wien, Österreich   \n",
       "2  5582988482                         Accenture        Österreich   \n",
       "3  5582082437  ANGEHEUERT GmbH Personalberatung  Wien, Österreich   \n",
       "4  5582082438  ANGEHEUERT GmbH Personalberatung        Österreich   \n",
       "\n",
       "                created   search_term  \n",
       "0  2026-01-15T21:42:20Z  Data Analyst  \n",
       "1  2026-01-15T02:15:16Z  Data Analyst  \n",
       "2  2026-01-13T21:37:41Z  Data Analyst  \n",
       "3  2026-01-13T11:32:57Z  Data Analyst  \n",
       "4  2026-01-13T11:32:57Z  Data Analyst  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = ['description', 'adref']\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Date Conversion\n",
    "\n",
    "Converting the `created` column to a standard `datetime` format. We use `errors='coerce'` to handle any malformed strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:28.321789Z",
     "iopub.status.busy": "2026-01-20T22:36:28.321789Z",
     "iopub.status.idle": "2026-01-20T22:36:28.397426Z",
     "shell.execute_reply": "2026-01-20T22:36:28.397426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dates after conversion: 0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39844 entries, 0 to 39843\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   country_code  39844 non-null  object             \n",
      " 1   title         39844 non-null  object             \n",
      " 2   id            39844 non-null  int64              \n",
      " 3   company       38511 non-null  object             \n",
      " 4   location      39844 non-null  object             \n",
      " 5   created       39844 non-null  datetime64[ns, UTC]\n",
      " 6   search_term   35361 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), int64(1), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df['created'] = pd.to_datetime(df['created'], errors='coerce')\n",
    "print(f\"Missing dates after conversion: {df['created'].isnull().sum()}\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "- **General Scope:** The dataset contains **39,844 jobs** across 19 countries for the Jan 1-15 period.\n",
    "- **Technical Depth:** Captures specialized roles (Data Engineer, Scientist, Analyst, MLOps, Architect).\n",
    "- **Quality Metrics:**\n",
    "    - **Titles:** Perfect coverage (0 nulls).\n",
    "    - **Companies:** 1,333 missing values (3.3%), appearing across multiple territories.\n",
    "    - **Dates:** All dates fall within the target range (Jan 1st - 15th).\n",
    "\n",
    "**Proposed Strategy:** Fill missing companies with \"Unknown\". We also have a `search_term` column for 35,361 records to enable role-based segment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:28.397426Z",
     "iopub.status.busy": "2026-01-20T22:36:28.397426Z",
     "iopub.status.idle": "2026-01-20T22:36:28.430462Z",
     "shell.execute_reply": "2026-01-20T22:36:28.429468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Null Counts per Column ---\n",
      "country_code       0\n",
      "title              0\n",
      "id                 0\n",
      "company         1333\n",
      "location           0\n",
      "created            0\n",
      "search_term     4483\n",
      "dtype: int64\n",
      "\n",
      "--- Sample of Rows with Null Company (First 10) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>created</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>au</td>\n",
       "      <td>Raw Materials Data Analyst - Rowville</td>\n",
       "      <td>5571054238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rowville, Knox Area</td>\n",
       "      <td>2026-01-07 17:18:20+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>5586963668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manaus, Amazonas</td>\n",
       "      <td>2026-01-15 18:16:36+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>br</td>\n",
       "      <td>Sales Operations &amp; Data Analyst</td>\n",
       "      <td>5586961494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:16:22+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6596</th>\n",
       "      <td>br</td>\n",
       "      <td>Analista De Powerbi Pleno</td>\n",
       "      <td>5586961442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brasilia, Distrito Federal</td>\n",
       "      <td>2026-01-15 18:16:21+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>5586961320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Porto Alegre, Rio Grande do Sul</td>\n",
       "      <td>2026-01-15 18:16:20+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>5586919512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:11:53+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>5586918259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:11:40+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>br</td>\n",
       "      <td>It Service Operations Engineer</td>\n",
       "      <td>5586965606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:16:48+00:00</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5586965000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:16:44+00:00</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>br</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>5586963650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Piracicaba, Estado de São Paulo</td>\n",
       "      <td>2026-01-15 18:16:36+00:00</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country_code                                  title          id company  \\\n",
       "1921           au  Raw Materials Data Analyst - Rowville  5571054238     NaN   \n",
       "6594           br                           Data Analyst  5586963668     NaN   \n",
       "6595           br        Sales Operations & Data Analyst  5586961494     NaN   \n",
       "6596           br              Analista De Powerbi Pleno  5586961442     NaN   \n",
       "6597           br                           Data Analyst  5586961320     NaN   \n",
       "6598           br                           Data Analyst  5586919512     NaN   \n",
       "6599           br                           Data Analyst  5586918259     NaN   \n",
       "6717           br         It Service Operations Engineer  5586965606     NaN   \n",
       "6718           br                          Data Engineer  5586965000     NaN   \n",
       "6719           br                          Data Engineer  5586963650     NaN   \n",
       "\n",
       "                             location                   created    search_term  \n",
       "1921              Rowville, Knox Area 2026-01-07 17:18:20+00:00   Data Analyst  \n",
       "6594                 Manaus, Amazonas 2026-01-15 18:16:36+00:00   Data Analyst  \n",
       "6595   São Paulo, Estado de São Paulo 2026-01-15 18:16:22+00:00   Data Analyst  \n",
       "6596       Brasilia, Distrito Federal 2026-01-15 18:16:21+00:00   Data Analyst  \n",
       "6597  Porto Alegre, Rio Grande do Sul 2026-01-15 18:16:20+00:00   Data Analyst  \n",
       "6598   São Paulo, Estado de São Paulo 2026-01-15 18:11:53+00:00   Data Analyst  \n",
       "6599   São Paulo, Estado de São Paulo 2026-01-15 18:11:40+00:00   Data Analyst  \n",
       "6717   São Paulo, Estado de São Paulo 2026-01-15 18:16:48+00:00  Data Engineer  \n",
       "6718   São Paulo, Estado de São Paulo 2026-01-15 18:16:44+00:00  Data Engineer  \n",
       "6719  Piracicaba, Estado de São Paulo 2026-01-15 18:16:36+00:00  Data Engineer  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(\"--- Null Counts per Column ---\")\n",
    "print(null_counts)\n",
    "\n",
    "print(\"\\n--- Sample of Rows with Null Company (First 10) ---\")\n",
    "if 'company' in df.columns:\n",
    "    display(df[df['company'].isnull()].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Status Check:** The data is mostly clean regarding mandatory fields (Title, Date, Location). The next step is to address internal consistency and redundant records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multi-Role & Record Redundancy Analysis\n",
    "\n",
    "Checking for exact row duplicates and unique job identifier matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:28.434706Z",
     "iopub.status.busy": "2026-01-20T22:36:28.434493Z",
     "iopub.status.idle": "2026-01-20T22:36:28.484675Z",
     "shell.execute_reply": "2026-01-20T22:36:28.483219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact row duplicates: 4\n",
      "Duplicate job IDs: 11819\n",
      "\n",
      "--- Sample of Rows with Duplicate IDs ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>created</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>Data Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>at</td>\n",
       "      <td>Senior Scientific Data Engineer- Vienna Austria</td>\n",
       "      <td>5570582894</td>\n",
       "      <td>TetraScience</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-06 22:25:57+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15 02:15:16+00:00</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15 02:15:16+00:00</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15 02:15:16+00:00</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>at</td>\n",
       "      <td>Product Owner - Data &amp; Analytics (f/m/d)</td>\n",
       "      <td>5585358198</td>\n",
       "      <td>Greentube GmbH</td>\n",
       "      <td>Wien, Österreich</td>\n",
       "      <td>2026-01-15 02:15:16+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country_code                                            title  \\\n",
       "15             at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "25             at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "68             at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "613            at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "764            at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "1310           at  Senior Scientific Data Engineer- Vienna Austria   \n",
       "31             at         Product Owner - Data & Analytics (f/m/d)   \n",
       "1              at         Product Owner - Data & Analytics (f/m/d)   \n",
       "739            at         Product Owner - Data & Analytics (f/m/d)   \n",
       "853            at         Product Owner - Data & Analytics (f/m/d)   \n",
       "\n",
       "              id         company          location                   created  \\\n",
       "15    5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "25    5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "68    5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "613   5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "764   5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "1310  5570582894    TetraScience  Wien, Österreich 2026-01-06 22:25:57+00:00   \n",
       "31    5585358198  Greentube GmbH  Wien, Österreich 2026-01-15 02:15:16+00:00   \n",
       "1     5585358198  Greentube GmbH  Wien, Österreich 2026-01-15 02:15:16+00:00   \n",
       "739   5585358198  Greentube GmbH  Wien, Österreich 2026-01-15 02:15:16+00:00   \n",
       "853   5585358198  Greentube GmbH  Wien, Österreich 2026-01-15 02:15:16+00:00   \n",
       "\n",
       "         search_term  \n",
       "15      Data Analyst  \n",
       "25    Data Architect  \n",
       "68     Data Engineer  \n",
       "613             Data  \n",
       "764   Data Scientist  \n",
       "1310             NaN  \n",
       "31     Data Engineer  \n",
       "1       Data Analyst  \n",
       "739   Data Scientist  \n",
       "853              NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exact_duplicates = df.duplicated().sum()\n",
    "id_duplicates = df.duplicated(subset=['id']).sum()\n",
    "\n",
    "print(f\"Exact row duplicates: {exact_duplicates}\")\n",
    "print(f\"Duplicate job IDs: {id_duplicates}\")\n",
    "\n",
    "if id_duplicates > 0:\n",
    "    print(\"\\n--- Sample of Rows with Duplicate IDs ---\")\n",
    "    # Show some examples of duplicated IDs to understand why they exist\n",
    "    duplicate_ids = df[df.duplicated(subset=['id'])]['id'].head(3)\n",
    "    display(df[df['id'].isin(duplicate_ids)].sort_values(by='id').head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Findings:** While there are no exact row duplicates, we found **11,819 duplicate job IDs**.\n",
    "\n",
    "**Revised Strategy:** Instead of treating these as 'junk' duplicates, we recognize that the same job can match multiple search terms (e.g., 'Data Engineer' and 'Big Data'). \n",
    "\n",
    "To preserve the richness of the classification, we will **not** drop these records yet. This allows us to perform a more accurate 'Market Demand' analysis by role in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial Cleaning (Execution)\n",
    "\n",
    "Applying the decisions made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-20T22:36:28.484675Z",
     "iopub.status.busy": "2026-01-20T22:36:28.484675Z",
     "iopub.status.idle": "2026-01-20T22:36:28.517677Z",
     "shell.execute_reply": "2026-01-20T22:36:28.516681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Shape after cleaning: (39844, 7)\n",
      "Total Unique Jobs (by ID): 28025\n",
      "\n",
      "Remaining missing values:\n",
      "country_code       0\n",
      "title              0\n",
      "id                 0\n",
      "company            0\n",
      "location           0\n",
      "created            0\n",
      "search_term     4483\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Note: We are KEEPING duplicate IDs to preserve multi-role classification\n",
    "# as decided in the Data Quality strategy update.\n",
    "\n",
    "# Remove null title (safety check)\n",
    "df = df.dropna(subset=['title'])\n",
    "\n",
    "# Fill null companies\n",
    "df['company'] = df['company'].fillna('Unknown')\n",
    "\n",
    "print(f\"Final Shape after cleaning: {df.shape}\")\n",
    "print(f\"Total Unique Jobs (by ID): {df['id'].nunique()}\")\n",
    "print(f\"\\nRemaining missing values:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Job Content Analysis:** Perform a frequency analysis of job titles to identify common roles.\n",
    "2. **Geographical Distribution:** Visualize job density across the different countries.\n",
    "3. **Time Series Exploration:** Analyze daily job posting counts to identify trends in early January.\n",
    "4. **Company Profiling:** identify the top recruiters in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
