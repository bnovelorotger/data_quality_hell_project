{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preliminary EDA - Data Quality Hell\n",
                "\n",
                "This notebook covers the initial inspection and cleaning of the consolidated jobs dataset. \n",
                "\n",
                "**Objective:** Prepare the data for deeper Exploratory Data Analysis (EDA) and future transformations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "# Set display options\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.max_colwidth', 100)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "\n",
                "We start with the merged dataset containing ~9,500 records from 19 countries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_csv = Path(\"../data/interim/all_jobs_merged.csv\")\n",
                "df = pd.read_csv(input_csv)\n",
                "print(f\"Initial Shape: {df.shape}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Drop Unnecessary Columns\n",
                "\n",
                "Columns `description` (too inconsistent) and `adref` (no analytical value) are dropped to simplify the analysis.\n",
                "\n",
                "> **Note:** We use `errors='ignore'` so the cell can be re-run without errors if the columns were already removed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_to_drop = ['description', 'adref']\n",
                "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Date Conversion\n",
                "\n",
                "Converting the `created` column to a standard `datetime` format. We use `errors='coerce'` to handle any malformed strings."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df['created'] = pd.to_datetime(df['created'], errors='coerce')\n",
                "print(f\"Missing dates after conversion: {df['created'].isnull().sum()}\")\n",
                "df.info()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Null Analysis\n",
                "\n",
                "Identifying columns with missing values and inspecting the problematic rows."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "null_counts = df.isnull().sum()\n",
                "print(\"--- Null Counts per Column ---\")\n",
                "print(null_counts)\n",
                "\n",
                "print(\"\\n--- Rows with Null Title ---\")\n",
                "display(df[df['title'].isnull()])\n",
                "\n",
                "print(\"\\n--- Sample of Rows with Null Company (First 10) ---\")\n",
                "display(df[df['company'].isnull()].head(10))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Findings:**\n",
                "- **Title:** 1 missing value. This row is missing critical information and should be removed.\n",
                "- **Company:** 319 missing values. Many of these seem to be valid jobs where the company name was simply not provided by the API.\n",
                "\n",
                "**Proposed Strategy:** Fill missing companies with \"Unknown\" and drop the single row missing a title."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Duplicate Analysis\n",
                "\n",
                "Checking for exact row duplicates across the key remaining columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "duplicates = df.duplicated().sum()\n",
                "print(f\"Duplicate rows: {duplicates}\")\n",
                "\n",
                "if duplicates > 0:\n",
                "    print(\"\\n--- Sample of Duplicated Rows ---\")\n",
                "    display(df[df.duplicated()].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Proposed Strategy:** Drop all 33 duplicates to ensure analysis integrity."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Initial Cleaning (Execution)\n",
                "\n",
                "Applying the decisions made above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove duplicates\n",
                "df = df.drop_duplicates()\n",
                "\n",
                "# Remove null title\n",
                "df = df.dropna(subset=['title'])\n",
                "\n",
                "# Fill null companies\n",
                "df['company'] = df['company'].fillna('Unknown')\n",
                "\n",
                "print(f\"Final Shape after cleaning: {df.shape}\")\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "1. Save this baseline cleaned version for EDA.\n",
                "2. Start analyzing job counts by country and time trends."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}